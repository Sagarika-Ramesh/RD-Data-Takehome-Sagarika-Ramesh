{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b40ef440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'METHOD 2 OF DATASET CREATION\\n\\nimport os\\nimport shutil\\nimport random\\n\\n# Specify the path to the source dataset directory\\nsource_dir = \"../celeba_dataset/img_align_celeba\"\\n\\n# Specify the path to the destination directory\\ndestination_dir = \"../celeba_dataset/celeb_faces_real\"\\n\\n# Number of images to randomly select and copy\\nnum_images_to_copy = 400\\n\\n# Create the destination directory if it doesn\\'t exist\\nos.makedirs(destination_dir, exist_ok=True)\\n\\n# List all image files in the source directory\\nimage_files = os.listdir(source_dir)\\n\\n# Randomly select images\\nselected_images = random.sample(image_files, num_images_to_copy)\\n\\n# Copy selected images to the destination directory\\nfor image in selected_images:\\n    src_path = os.path.join(source_dir, image)\\n    dst_path = os.path.join(destination_dir, image)\\n    shutil.copy(src_path, dst_path)\\n\\nprint(f\"Selected and copied {num_images_to_copy} random images to the destination directory.\")\\n\\ndataset = keras.utils.image_dataset_from_directory(\\n    \"../celeb_faces_real\", label_mode=None, image_size=(64, 64), batch_size=32\\n)\\ndataset = dataset.map(lambda x: x / 255.0)\\n\\nimage_path = \"../celeb_faces_real/000049.jpg\"\\n\\n# Open the image using PIL\\nimg = Image.open(image_path)\\n\\n# Get the size (dimensions) of the image\\nwidth, height = img.size\\nprint(width, height)\\n\\nfor x in dataset:\\n    plt.axis(\"off\")\\n    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\\n    break\\n    \\n'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"METHOD 2 OF DATASET CREATION\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Specify the path to the source dataset directory\n",
    "source_dir = \"../celeba_dataset/img_align_celeba\"\n",
    "\n",
    "# Specify the path to the destination directory\n",
    "destination_dir = \"../celeba_dataset/celeb_faces_real\"\n",
    "\n",
    "# Number of images to randomly select and copy\n",
    "num_images_to_copy = 400\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# List all image files in the source directory\n",
    "image_files = os.listdir(source_dir)\n",
    "\n",
    "# Randomly select images\n",
    "selected_images = random.sample(image_files, num_images_to_copy)\n",
    "\n",
    "# Copy selected images to the destination directory\n",
    "for image in selected_images:\n",
    "    src_path = os.path.join(source_dir, image)\n",
    "    dst_path = os.path.join(destination_dir, image)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(f\"Selected and copied {num_images_to_copy} random images to the destination directory.\")\n",
    "\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    \"../celeb_faces_real\", label_mode=None, image_size=(64, 64), batch_size=32\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n",
    "\n",
    "image_path = \"../celeb_faces_real/000049.jpg\"\n",
    "\n",
    "# Open the image using PIL\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Get the size (dimensions) of the image\n",
    "width, height = img.size\n",
    "print(width, height)\n",
    "\n",
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ad8e51e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'discriminator = keras.Sequential(\\n    [\\n        keras.Input(shape=(64, 64, 3)),\\n        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Flatten(),\\n        layers.Dropout(0.2),\\n        layers.Dense(1, activation=\"sigmoid\"),\\n    ],\\n    name=\"discriminator\",\\n)\\ndiscriminator.summary()\\n\\nlatent_dim = 128\\n\\ngenerator = keras.Sequential(\\n    [\\n        keras.Input(shape=(latent_dim,)),\\n        layers.Dense(8 * 8 * 128),\\n        layers.Reshape((8, 8, 128)),\\n        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\\n        layers.LeakyReLU(alpha=0.2),\\n        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\\n    ],\\n    name=\"generator\",\\n)\\ngenerator.summary()\\n\\nclass GAN(keras.Model):\\n    def __init__(self, discriminator, generator, latent_dim):\\n        super().__init__()\\n        self.discriminator = discriminator\\n        self.generator = generator\\n        self.latent_dim = latent_dim\\n\\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\\n        super().compile()\\n        self.d_optimizer = d_optimizer\\n        self.g_optimizer = g_optimizer\\n        self.loss_fn = loss_fn\\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\\n\\n    @property\\n    def metrics(self):\\n        return [self.d_loss_metric, self.g_loss_metric]\\n        \\n    class GANMonitor(keras.callbacks.Callback):\\n    def __init__(self, num_img=3, latent_dim=128):\\n        self.num_img = num_img\\n        self.latent_dim = latent_dim\\n\\n    def on_epoch_end(self, epoch, logs=None):\\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\\n        generated_images = self.model.generator(random_latent_vectors)\\n        generated_images *= 255\\n        generated_images.numpy()\\n        for i in range(self.num_img):\\n            img = keras.utils.array_to_img(generated_images[i])\\n            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\\n        \\n\\n'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()\n",
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "        \n",
    "    class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n",
    "        \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b0d8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128,  image_size=(178, 218)):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img = img.resize(self.image_size)\n",
    "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n",
    "            def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "            epochs = 30  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=20, latent_dim=latent_dim)]\n",
    ")\n",
    "        }\n",
    "        \n",
    "        \n",
    "\n",
    "# Specify the folder path where the generated_img.png files are located\n",
    "folder_path = \"./\"\n",
    "        #print(f\"Deleted {file_path}\")\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512c56e",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c54761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 21:05:59.000067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689e65c",
   "metadata": {},
   "source": [
    "### DATASET CREATION\n",
    "\n",
    "The below code is written to organize a dataset of face images into training and validation sets. My goal is to split the dataset with an 80/20 ratio.\n",
    "I've defined source and destination directories for my dataset.\n",
    "To ensure randomness in the split, I've shuffled the list of files.\n",
    "Then, I've separated the shuffled list of files into two sets: one for training and one for validation, based on the calculated split index.\n",
    "I've copied the files from the source directory to their respective training and validation directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6465c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1081, Training files: 864, Validation files: 217\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "source_dir = '../dataset/face_dataset/face_real'  \n",
    "train_dir = '../dataset/face_dataset/train/face_real'  \n",
    "val_dir = '../dataset/face_dataset/validation/face_real'\n",
    "\n",
    "# Define the split ratio (e.g., 80% for training, 20% for validation)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory (assuming all files are images)\n",
    "files = os.listdir(source_dir)\n",
    "\n",
    "# Shuffle the list of files randomly\n",
    "random.shuffle(files)\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(files) * split_ratio)\n",
    "\n",
    "# Split the files into training and validation sets\n",
    "train_files = files[:split_index]\n",
    "val_files = files[split_index:]\n",
    "\n",
    "# Copy the files to the respective directories\n",
    "for file in train_files:\n",
    "    src = os.path.join(source_dir, file)\n",
    "    dst = os.path.join(train_dir, file)\n",
    "    copyfile(src, dst)\n",
    "\n",
    "for file in val_files:\n",
    "    src = os.path.join(source_dir, file)\n",
    "    dst = os.path.join(val_dir, file)\n",
    "    copyfile(src, dst)\n",
    "\n",
    "print(f\"Total files: {len(files)}, Training files: {len(train_files)}, Validation files: {len(val_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ecec0233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 960, Training files: 768, Validation files: 192\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "source_dir = '../dataset/face_dataset/face_fake'  \n",
    "train_dir = '../dataset/face_dataset/train/face_fake'  \n",
    "val_dir = '../dataset/face_dataset/validation/face_fake'\n",
    "\n",
    "# Define the split ratio (e.g., 80% for training, 20% for validation)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory (assuming all files are images)\n",
    "files = os.listdir(source_dir)\n",
    "\n",
    "# Shuffle the list of files randomly\n",
    "random.shuffle(files)\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(files) * split_ratio)\n",
    "\n",
    "# Split the files into training and validation sets\n",
    "train_files = files[:split_index]\n",
    "val_files = files[split_index:]\n",
    "\n",
    "# Copy the files to the respective directories\n",
    "for file in train_files:\n",
    "    src = os.path.join(source_dir, file)\n",
    "    dst = os.path.join(train_dir, file)\n",
    "    copyfile(src, dst)\n",
    "\n",
    "for file in val_files:\n",
    "    src = os.path.join(source_dir, file)\n",
    "    dst = os.path.join(val_dir, file)\n",
    "    copyfile(src, dst)\n",
    "\n",
    "print(f\"Total files: {len(files)}, Training files: {len(train_files)}, Validation files: {len(val_files)}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77ac7d50",
   "metadata": {},
   "source": [
    "I've configured an `ImageDataGenerator` with the following settings:\n",
    "\n",
    "I have performed Data augmentation by enabled horizontal and vertical flipping fo images, which will randomly flip some images vertically during training.\n",
    "I have performed image preprocessing by rescaled the pixel values of the images to a range between 0 and 1 (`rescale=1./255`).\n",
    "I've set a validation split of 20%.\n",
    "\n",
    "Next, I've created two data generators for training and validation data:\n",
    "\n",
    "- The `train` data generator is configured to flow from the directory \"../dataset/face_dataset/train/\". It's set to work in binary classification mode (`class_mode=\"binary\"`) and resize images to a target size of 224x224 pixels. Each batch will contain 64 images.\n",
    "- Similarly, the `val` data generator flows from the directory \"../dataset/face_dataset/validation/\", operates in binary classification mode, resizes images to 224x224 pixels, and uses batches of 64 images.\n",
    "\n",
    "These data generators will be used to load and preprocess the training and validation datasets for feeding into a deep learning model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0884debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1632 images belonging to 2 classes.\n",
      "Found 409 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 22 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_with_aug = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   rescale=1./255,\n",
    "                                  validation_split=0.2)\n",
    "train = data_with_aug.flow_from_directory(\"../dataset/face_dataset/train/\",\n",
    "                                          class_mode=\"binary\",\n",
    "                                          target_size=(224, 224),\n",
    "                                          batch_size=64)\n",
    "\n",
    "val = data_with_aug.flow_from_directory(\"../dataset/face_dataset/validation/\",\n",
    "                                          class_mode=\"binary\",\n",
    "                                          target_size=(224, 224),\n",
    "                                          batch_size=64)\n",
    "test = data_with_aug.flow_from_directory(\"../dataset/face_dataset/test/\",\n",
    "                                          class_mode=\"binary\",\n",
    "                                          target_size=(224, 224),\n",
    "                                          batch_size=64)\n",
    "real_test = data_with_aug.flow_from_directory(\"../rd_test_dataset/\",\n",
    "                                          class_mode=\"binary\",\n",
    "                                          target_size=(224, 224),\n",
    "                                          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f299b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_fake': 0, 'face_real': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfcc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3f77e69",
   "metadata": {},
   "source": [
    "I've harnessed the power of transfer learning to achieve higher performance in my project. For this purpose, I opted for a VGG model, notably VGG-16, which, during its development, had outperformed the competition in the ImageNet photo classification challenge.\n",
    "\n",
    "This model consists of two fundamental components: the feature extraction part, composed of VGG blocks that excel at capturing image details, and the classifier part, consisting of fully connected layers culminating in an output layer.\n",
    "\n",
    "To adapt this model to my task of discerning real from fake faces, I strategically leveraged the feature extraction segment. Here's the key strategy:\n",
    "\n",
    "- I maintained the convolutional layers' weights unaltered during training, benefiting from their ability to detect meaningful features in images.\n",
    "- I introduced a classifier segment tailored specifically to the real and fake face dataset. This classifier, composed of fully connected layers, it is designed to interpret the features extracted by the pre-trained layers and perform a binary classification, efficiently categorizing the images as either real or fake.\n",
    "\n",
    "This approach harnesses the strengths of transfer learning, making use of a pre-trained feature extractor while fine-tuning the model to excel in distinguishing between genuine and manipulated facial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b11f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "\n",
    " model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    " for layer in model.layers:\n",
    "     layer.trainable = False\n",
    "     flat1 = Flatten()(model.layers[-1].output)\n",
    "    #Fully connected layer with 2048 units and ReLU activation\n",
    "     class1 = Dense(2048, activation='relu')(flat1)\n",
    "     output = Dense(1, activation='sigmoid')(class1)#output layer with sigmoid activation function\n",
    " model = Model(inputs=model.inputs, outputs=output)\n",
    " \n",
    " model.compile(loss='binary_crossentropy',optimizer=Adam(0.0002), metrics=['acc'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec12be3e",
   "metadata": {},
   "source": [
    "The below code is used to create and save a plot summarizing a deep learning model's training and validation performance. It plots both the loss and accuracy over training epochs and saves the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6cbc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    " # plot loss\n",
    " plt.subplot(211)\n",
    " plt.title('Cross Entropy Loss')\n",
    " plt.plot(history.history['loss'], color='blue', label='train')\n",
    " plt.plot(history.history['val_loss'], color='orange', label='val')\n",
    " # plot accuracy\n",
    " plt.subplot(212)\n",
    " plt.title('Classification Accuracy')\n",
    " plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    " plt.plot(history.history['val_accuracy'], color='orange', label='val')\n",
    " # save plot to file\n",
    " filename = sys.argv[0].split('/')[-1]\n",
    " plt.savefig(filename + '_plot.png')\n",
    " plt.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "efe09736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "60466125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/32b6q6xx5cs1rsv6b_0g311c0000gn/T/ipykernel_47701/1498492493.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train, steps_per_epoch=len(train),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26/26 [==============================] - ETA: 0s - loss: 1.5715 - acc: 0.5270WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f785c6b14c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7f785c6b14c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f785c6b14c0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7f785c6b14c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "26/26 [==============================] - 287s 11s/step - loss: 1.5715 - acc: 0.5270 - val_loss: 0.6604 - val_acc: 0.5892\n",
      "Epoch 2/30\n",
      "26/26 [==============================] - 291s 11s/step - loss: 0.6210 - acc: 0.6624 - val_loss: 0.6136 - val_acc: 0.6748\n",
      "Epoch 3/30\n",
      "26/26 [==============================] - 285s 11s/step - loss: 0.5916 - acc: 0.6893 - val_loss: 0.6348 - val_acc: 0.6333\n",
      "Epoch 4/30\n",
      "26/26 [==============================] - 276s 11s/step - loss: 0.5786 - acc: 0.6985 - val_loss: 0.6246 - val_acc: 0.6210\n",
      "Epoch 5/30\n",
      "26/26 [==============================] - 278s 11s/step - loss: 0.5446 - acc: 0.7316 - val_loss: 0.6224 - val_acc: 0.6699\n",
      "Epoch 6/30\n",
      "26/26 [==============================] - 287s 11s/step - loss: 0.5229 - acc: 0.7377 - val_loss: 0.6128 - val_acc: 0.6797\n",
      "Epoch 7/30\n",
      "26/26 [==============================] - 326s 13s/step - loss: 0.5034 - acc: 0.7518 - val_loss: 0.6366 - val_acc: 0.6455\n",
      "Epoch 8/30\n",
      "26/26 [==============================] - 307s 12s/step - loss: 0.4859 - acc: 0.7665 - val_loss: 0.6286 - val_acc: 0.6577\n",
      "Epoch 9/30\n",
      "26/26 [==============================] - 300s 12s/step - loss: 0.5003 - acc: 0.7604 - val_loss: 0.7104 - val_acc: 0.6112\n",
      "Epoch 10/30\n",
      "26/26 [==============================] - 296s 12s/step - loss: 0.4909 - acc: 0.7659 - val_loss: 0.6802 - val_acc: 0.6504\n",
      "Epoch 11/30\n",
      "26/26 [==============================] - 332s 13s/step - loss: 0.4717 - acc: 0.7708 - val_loss: 0.6491 - val_acc: 0.6430\n",
      "Epoch 12/30\n",
      "26/26 [==============================] - 360s 14s/step - loss: 0.4140 - acc: 0.8229 - val_loss: 0.6615 - val_acc: 0.6577\n",
      "Epoch 13/30\n",
      "26/26 [==============================] - 300s 12s/step - loss: 0.4088 - acc: 0.8223 - val_loss: 0.7656 - val_acc: 0.5795\n",
      "Epoch 14/30\n",
      "26/26 [==============================] - 300s 12s/step - loss: 0.4074 - acc: 0.8205 - val_loss: 0.7044 - val_acc: 0.6406\n",
      "Epoch 15/30\n",
      "26/26 [==============================] - 1919s 76s/step - loss: 0.3987 - acc: 0.8260 - val_loss: 0.7397 - val_acc: 0.6259\n",
      "Epoch 16/30\n",
      "26/26 [==============================] - 303s 12s/step - loss: 0.3553 - acc: 0.8529 - val_loss: 0.6913 - val_acc: 0.6333\n",
      "Epoch 17/30\n",
      "26/26 [==============================] - 294s 11s/step - loss: 0.3698 - acc: 0.8431 - val_loss: 0.7666 - val_acc: 0.6235\n",
      "Epoch 18/30\n",
      "26/26 [==============================] - 298s 12s/step - loss: 0.3564 - acc: 0.8376 - val_loss: 0.6596 - val_acc: 0.6748\n",
      "Epoch 19/30\n",
      "26/26 [==============================] - 284s 11s/step - loss: 0.3586 - acc: 0.8388 - val_loss: 0.7046 - val_acc: 0.6528\n",
      "Epoch 20/30\n",
      "26/26 [==============================] - 262s 10s/step - loss: 0.3215 - acc: 0.8732 - val_loss: 0.6939 - val_acc: 0.6406\n",
      "Epoch 21/30\n",
      "26/26 [==============================] - 247s 10s/step - loss: 0.2920 - acc: 0.9001 - val_loss: 0.7315 - val_acc: 0.6064\n",
      "Epoch 22/30\n",
      "26/26 [==============================] - 232s 9s/step - loss: 0.2696 - acc: 0.9105 - val_loss: 0.7814 - val_acc: 0.6210\n",
      "Epoch 23/30\n",
      "26/26 [==============================] - 231s 9s/step - loss: 0.2811 - acc: 0.8897 - val_loss: 0.8209 - val_acc: 0.6137\n",
      "Epoch 24/30\n",
      "26/26 [==============================] - 224s 9s/step - loss: 0.2782 - acc: 0.8958 - val_loss: 0.7088 - val_acc: 0.6601\n",
      "Epoch 25/30\n",
      "26/26 [==============================] - 223s 9s/step - loss: 0.2419 - acc: 0.9246 - val_loss: 0.7639 - val_acc: 0.6504\n",
      "Epoch 26/30\n",
      "26/26 [==============================] - 220s 9s/step - loss: 0.2275 - acc: 0.9301 - val_loss: 0.7941 - val_acc: 0.6259\n",
      "Epoch 27/30\n",
      "26/26 [==============================] - 221s 9s/step - loss: 0.2119 - acc: 0.9265 - val_loss: 0.7376 - val_acc: 0.6601\n",
      "Epoch 28/30\n",
      "26/26 [==============================] - 221s 9s/step - loss: 0.2167 - acc: 0.9326 - val_loss: 0.7710 - val_acc: 0.6406\n",
      "Epoch 29/30\n",
      "26/26 [==============================] - 222s 9s/step - loss: 0.1977 - acc: 0.9412 - val_loss: 0.7964 - val_acc: 0.6210\n",
      "Epoch 30/30\n",
      "26/26 [==============================] - 229s 9s/step - loss: 0.1830 - acc: 0.9430 - val_loss: 0.7491 - val_acc: 0.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/32b6q6xx5cs1rsv6b_0g311c0000gn/T/ipykernel_47701/1498492493.py:5: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(val, steps=len(val), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 61.369\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train, steps_per_epoch=len(train),\n",
    "validation_data=val, validation_steps=len(val), epochs=30, verbose=1)\n",
    " # save model\n",
    "model.save('final_model.h5')\n",
    "_, acc = model.evaluate_generator(val, steps=len(val), verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c5ab7684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f785cb06df0>]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2dd510f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f785c6cf940>]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['acc'], color='blue', label='train')\n",
    "plt.plot(history.history['val_acc'], color='orange', label='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f4a66ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = sys.argv[0].split('/')[-1]\n",
    "plt.savefig(filename + '_plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "265ff7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 32s 7s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test)\n",
    "y_test = test.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9070568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "#print(\"ROC-AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "\n",
    "threshold = 0.5\n",
    "pred = (y_pred > threshold).astype(int)\n",
    "\n",
    "accuracy = (pred == y_test).mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "860627e5",
   "metadata": {},
   "source": [
    "1. Design & build a small dataset (about 100+ images) to differentiate between real and fake face images. Please explain:\n",
    "   \n",
    " \n",
    "a. Considerations that went into deciding what data to collect.\n",
    "Answer: \n",
    "I have tried to build the dataset using 2 different methods:\n",
    "Method1:\n",
    "Data for Train and Validation:\n",
    "Real images are obtained from Flickr. (Flickr-Faces-HQ (FFHQ)). 1082 random images are selected.\n",
    "Fake images are obtained from A Style-Based Generator Architecture for Generative Adversarial Networks created by\n",
    "Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA). It is made publicly available for research purposes.\n",
    "961 random images are selected. The data set is not imbalanced. There is no bias as the dataset contains people from different regions, race, age, gender and pose.\n",
    "\n",
    "Data for Test(Unseen Data):\n",
    "For test set, I have collected data from seperate source to avoid data leakage. Data is obtained from Computational Intelligence and Photography Lab,Department of Computer Science, Yonsei University.\n",
    "The data is expert-generated high-quality photoshopped face images. These images are not obtained from GAN.\n",
    "\n",
    "Method2:\n",
    "I have chosen to use CelebA data. \n",
    "Firstly, I wanted a data set that is publicly accessible to everyone.\n",
    "CelebA data contains 200,000+ images of celebrity faces and it includes diversity with people belonging to different races, genders,and ages. This data can be used as Real face Images.\n",
    "Fake Face images are then created using DCGAN(Deep Convolutional Generative Adversarial Network). \n",
    "I tried to generate fake face images using this method but it was very time consuming to train the model and generate a deep fake face image. \n",
    "\n",
    "b. How you went about collecting the data.\n",
    "Answer: I randomly selected around 1000 images from both fake and real images.\n",
    "For test dataset, seperate source is used and around 200 of real and fake images are collected.\n",
    "These images are placed under dataset folder.\n",
    "--\n",
    "Data set was downloaded from http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html website.\n",
    "I select random 400 images from that dataset to create celeb_face_real dataset.\n",
    "DCGA(Deep convolutional generative Adversarial network)was used to generate fake face images from the real face images. 80 epochs are run and the images generated after each epoch are stored in celeb_face_fake folder.\n",
    "\n",
    "\n",
    "c. Besides fake/real labels, what other labels would you consider? Explain a simple method to sample a uniform dataset in the i.i.d sense, given the labels.\n",
    "Answer: Beside real/fake labels, I can consider the facial expression of a person(angry, sad, happy..) as labels. \n",
    "I can also try to recognize try to classify as a person with glasses or without glasses. \n",
    "There are many more.\n",
    "\n",
    "d. What API (e.g Pandas, etc.) you used to store and organize meta information about the dataset.\n",
    "Answer:YAML file is used to store information about the image dataset in a structured format.\n",
    "        It contains dataset name, creation date, author name, classes/categories, number of images, size and resolution of images, version of the meta data.\n",
    "\n",
    "e. Please share your mini-dataset as a zip file\n",
    "The zipfile is in the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41e03936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_cnn_model():\n",
    "    model_cnn = keras.Sequential()\n",
    "    model_cnn.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)))\n",
    "    model_cnn.add(keras.layers.MaxPool2D(2,2))\n",
    "    model_cnn.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
    "    model_cnn.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "    model_cnn.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model_cnn.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "    model_cnn.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
    "    model_cnn.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "    model_cnn.add(keras.layers.Flatten())\n",
    "\n",
    "    model_cnn.add(keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "    model_cnn.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    model_cnn.compile(loss='binary_crossentropy',optimizer=Adam(0.0002), metrics=['acc'])\n",
    "    return model_cnn\n",
    " \n",
    "\n",
    "model_cnn = define_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c9647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.6932 - acc: 0.5255 - val_loss: 0.6913 - val_acc: 0.5232\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 55s 2s/step - loss: 0.6898 - acc: 0.5364 - val_loss: 0.6827 - val_acc: 0.5697\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 55s 2s/step - loss: 0.6772 - acc: 0.5975 - val_loss: 0.6645 - val_acc: 0.6064\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.6748 - acc: 0.5765 - val_loss: 0.6634 - val_acc: 0.6186\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.6650 - acc: 0.6142 - val_loss: 0.6595 - val_acc: 0.5892\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 58s 2s/step - loss: 0.6700 - acc: 0.5989 - val_loss: 0.6503 - val_acc: 0.6235\n",
      "Epoch 7/30\n",
      " 6/25 [======>.......................] - ETA: 37s - loss: 0.6668 - acc: 0.5911"
     ]
    }
   ],
   "source": [
    "hist2 = model_cnn.fit(train,\n",
    "         steps_per_epoch = 25,\n",
    "         epochs = 30,\n",
    "         validation_data = val)\n",
    "\n",
    "model_cnn.save('final2_model.h5')\n",
    "_, acc = model_cnn.evaluate(val, steps=len(val), verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed774fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(hist2.history['loss'], color='blue', label='train')\n",
    "plt.plot(hist2.history['val_loss'], color='orange', label='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(hist2.history['acc'], color='blue', label='train')\n",
    "plt.plot(hist2.history['val_acc'], color='orange', label='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae535af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model_cnn.predict(test)\n",
    "y_test2 = test.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "366b52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b088c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
      "58909280/58909280 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 2048)              51382272  \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,099,009\n",
      "Trainable params: 66,099,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGGFace(include_top=False, input_shape = (224,224,3))\n",
    "\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "flat_layer = Flatten(name='flatten')(last_layer)\n",
    "fc1 = Dense(2048, activation='relu', name='fc1')(flat_layer)\n",
    "dense2 = Dense(1, activation='sigmoid', name='dense2')(fc1)\n",
    "\n",
    "custom_vgg_model = Model(vgg_model.input, dense2)\n",
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c15c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(0.0002), \n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = custom_vgg_model.fit(train,\n",
    "         steps_per_epoch = 25,\n",
    "         epochs = 10,\n",
    "         validation_data = val)\n",
    "\n",
    "model_cnn.save('final3_model.h5')\n",
    "_, acc = custom_vgg_model.evaluate(val, steps=len(val), verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec484463",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.save('vggface_v1.h5')\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = custom_vgg_model.predict(real_test)\n",
    "y_test = real_test.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a74666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#print()\n",
    "#print(metrics.classification_report(y_test, y_pred > 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
